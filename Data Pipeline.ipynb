{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning-python in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightning-python)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest->lightning-python)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /opt/conda/lib/python3.6/site-packages (from pytest->lightning-python)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest->lightning-python)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest->lightning-python)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2->lightning-python)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->lightning-python)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->lightning-python)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->lightning-python)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->lightning-python)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /opt/conda/lib/python3.6/site-packages (from matplotlib->lightning-python)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from matplotlib->lightning-python)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from matplotlib->lightning-python)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->lightning-python)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightning-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark import SparkContext as sc\n",
    "from pyspark.sql.functions import col, split, ltrim, substring\n",
    "import pyspark.sql as SQL\n",
    "from pyspark.sql.functions import unix_timestamp, from_unixtime, date_format, \\\n",
    "        from_utc_timestamp, to_utc_timestamp, date_format, dayofmonth, monotonically_increasing_id\n",
    "import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Jan-01').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5044667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download and decompress data into your Jupyter environment; abreviated jan 2017 data\n",
    "jan_2017 = spark.read.format(\"csv\").load('yellow_tripdata_half.csv', header = True).cache()\n",
    "jan_2017.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get two dataframes to merge on, or else get cartesian product error\n",
    "taxi_zone = spark.read.format(\"csv\").load('taxi+_zone_lookup.csv', header = True)\n",
    "# taxi_zone2 = spark.read.format(\"csv\").load('taxi+_zone_lookup.csv', header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_zone.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging to get destination information\n",
    "jan_2017 = jan_2017.join(taxi_zone, jan_2017.PULocationID == taxi_zone.LocationID, \"left_outer\"). \\\n",
    "                withColumnRenamed(\"Borough\", \"PUBorough\").withColumnRenamed(\"Zone\", \"PUZone\").withColumnRenamed(\"service_zone\", \"PUServiceZone\").\\\n",
    "                withColumnRenamed(\"neighborhood\", \"PUneighbor\").cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.withColumn(\"uniqueIdColumn\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #merging to get destination information\n",
    "# jan_2017 = jan_2017.join(taxi_zone2, jan_2017.DOLocationID == taxi_zone2.LocationID, \"left_outer\"). \\\n",
    "#                 withColumnRenamed(\"Borough\", \"DOBorough\").withColumnRenamed(\"Zone\", \"DOZone\").withColumnRenamed(\"service_zone\", \"DOServiceZone\").\\\n",
    "#                 withColumnRenamed(\"neighborhood\", \"DOneighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017 = jan_2017.drop(\"LocationID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding if pickup is an aiport\n",
    "jan_2017 = jan_2017.withColumn(\"AirportPU\", \\\n",
    "                               F.when((jan_2017[\"PULocationID\"] == '138' ) & \\\n",
    "                                      (jan_2017[\"PULocationID\"] == '132'),1).otherwise(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.where((jan_2017['PUBorough'] != 'Unknown'))\n",
    "# jan_2017.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting date and time into different columns, casting date into date type\n",
    "split_pickup_col = split(jan_2017['tpep_pickup_datetime'], ' ')\n",
    "# split_dropoff_col = split(jan_2017['tpep_dropoff_datetime'], ' ')\n",
    "jan_2017 = jan_2017.withColumn(\"PUDate\", split_pickup_col.getItem(0).cast(DateType()))\n",
    "jan_2017 = jan_2017.withColumn(\"PUTime\", split_pickup_col.getItem(1))\n",
    "# jan_2017 = jan_2017.withColumn(\"DODate\", split_dropoff_col.getItem(0).cast(DateType()))\n",
    "# jan_2017 = jan_2017.withColumn(\"DOTime\", split_dropoff_col.getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting time into hour and minute; will round minute to nearest 5 minutes\n",
    "split_PUTime = split(jan_2017['PUTime'], ':')\n",
    "jan_2017 = jan_2017.withColumn(\"PUHour\", split_PUTime.getItem(0).cast(IntegerType()))\n",
    "jan_2017 = jan_2017.withColumn(\"PUMinute\", split_PUTime.getItem(1).cast(IntegerType()))\n",
    "\n",
    "# split_DOTime = split(jan_2017['DOTime'], ':')\n",
    "# jan_2017 = jan_2017.withColumn(\"DOHour\", split_DOTime.getItem(0).cast(IntegerType()))\n",
    "# jan_2017 = jan_2017.withColumn(\"DOMinute\", split_DOTime.getItem(1).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.withColumn(\"MorningRushHour\", \\\n",
    "                               F.when((jan_2017[\"PUHour\"] >= 6 ) & \\\n",
    "                                      (jan_2017[\"PUHour\"] < 9),1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.withColumn(\"EveningRushHour\", \\\n",
    "                               F.when((jan_2017[\"PUHour\"] >= 17 ) & \\\n",
    "                                      (jan_2017[\"PUHour\"] < 21),1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofyear\n",
    "jan_2017 = jan_2017.withColumn(\"PUDay\", dayofyear(jan_2017.PUDate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rounding down mintue to closest 5 minute mark (computationally easier)\n",
    "#jan_2017 = jan_2017.withColumn(\"DOMinute\", (jan_2017.DOMinute - jan_2017.DOMinute%5))\n",
    "jan_2017 = jan_2017.withColumn(\"PUMinute\", (jan_2017.PUMinute - jan_2017.PUMinute%5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOW gives you 1 (Monday) - 7 (Sunday)\n",
    "jan_2017 = jan_2017.withColumn(\"PU_DOW\",  date_format(jan_2017.PUDate, 'u').cast(ShortType()))\n",
    "#jan_2017 = jan_2017.withColumn(\"DO_DOW\",  date_format(jan_2017.DODate, 'u').cast(ShortType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding if destination is a weekend\n",
    "jan_2017 = jan_2017.withColumn(\"Weekend\", \\\n",
    "                               F.when((jan_2017[\"PU_DOW\"] == 7) | \\\n",
    "                                      (jan_2017[\"PU_DOW\"] == 6),1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.withColumn(\"WorkingHour\", \\\n",
    "                               F.when((((jan_2017[\"PUHour\"] >= 9 ) & (jan_2017[\"PUHour\"] < 17))\\\n",
    "                                       & (jan_2017[\"Weekend\"] == 0)) ,1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#casting data types to primitives\n",
    "\n",
    "#1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.\n",
    "jan_2017 = jan_2017.withColumn(\"VendorID\", jan_2017[\"VendorID\"].cast(ShortType()))\n",
    "\n",
    "jan_2017 = jan_2017.withColumn(\"passenger_count\", jan_2017[\"passenger_count\"].cast(ShortType()))\n",
    "\n",
    "#in miles\n",
    "jan_2017 = jan_2017.withColumn(\"trip_distance\", jan_2017[\"trip_distance\"].cast(FloatType()))\n",
    "\n",
    "#1= Credit card\n",
    "#2= Cash\n",
    "#3= No charge\n",
    "#4= Dispute\n",
    "#5= Unknown\n",
    "#6= Voided trip\n",
    "jan_2017 = jan_2017.withColumn(\"payment_type\", jan_2017[\"payment_type\"].cast(ShortType()))\n",
    "jan_2017 = jan_2017.withColumn(\"fare_amount\", jan_2017[\"fare_amount\"].cast(FloatType()))\n",
    "\n",
    "#0.50 and $1 rush hour and overnight charges.\n",
    "jan_2017 = jan_2017.withColumn(\"extra\", jan_2017[\"extra\"].cast(FloatType()))\n",
    "#.50, automatic MTA charge\n",
    "jan_2017 = jan_2017.withColumn(\"mta_tax\", jan_2017[\"mta_tax\"].cast(FloatType()))\n",
    "\n",
    "\n",
    "jan_2017 = jan_2017.withColumn(\"tip_amount\", jan_2017[\"tip_amount\"].cast(FloatType()))\n",
    "jan_2017 = jan_2017.withColumn(\"tolls_amount\", jan_2017[\"tolls_amount\"].cast(FloatType()))\n",
    "jan_2017 = jan_2017.withColumn(\"improvement_surcharge\", jan_2017[\"improvement_surcharge\"].cast(FloatType()))\n",
    "jan_2017 = jan_2017.withColumn(\"total_amount\", jan_2017[\"total_amount\"].cast(FloatType()))\n",
    "\n",
    "\n",
    "jan_2017 = jan_2017.withColumn(\"RateCodeID\", jan_2017[\"RateCodeID\"].cast(ShortType()))\n",
    "#1= Standard rate\n",
    "#2=JFK -> $52 flat fare\n",
    "#3=Newark\n",
    "#4=Nassau or Westchester\n",
    "#5=Negotiated fare\n",
    "#6=Group ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column for looking at average dollar/mile, will used for filtering: should be around $2.5 per mile according to MTA\n",
    "#use fare amount because tips can be large if generous \n",
    "# jan_2017 = jan_2017.withColumn(\"cost_per_mile\", (jan_2017[\"fare_amount\"]/jan_2017[\"trip_distance\"]).cast(FloatType()))\n",
    "#column for looking at average miles per dollar, will be used for filtering: should be around 0.4 miles per dollar\n",
    "#use fare amount because tips can be large if generous \n",
    "# jan_2017 = jan_2017.withColumn(\"miles_per_dollar\", (jan_2017[\"trip_distance\"]/jan_2017[\"fare_amount\"]).cast(FloatType()))\n",
    "\n",
    "#use fare amount because tips can be large if generous \n",
    "# jan_2017 = jan_2017.withColumn(\"missing_money\", (jan_2017[\"total_amount\"]-jan_2017[\"fare_amount\"]-jan_2017[\"extra\"] \\\n",
    "#                                                  - jan_2017[\"mta_tax\"] - jan_2017[\"tip_amount\"] - jan_2017[\"tolls_amount\"] \\\n",
    "#                                                  - jan_2017[\"improvement_surcharge\"]).cast(FloatType()))\n",
    "                                                \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic fare cleaning, ensure that all values are above zero\n",
    "jan_2017 = jan_2017.filter(jan_2017.tip_amount >= 0)\n",
    "jan_2017 = jan_2017.filter(jan_2017.tolls_amount >= 0.0) \n",
    "jan_2017 = jan_2017.filter(jan_2017.total_amount >= 3.30)\n",
    "jan_2017 = jan_2017.filter(jan_2017.extra >= 0.00)\n",
    "#jan_2017 = jan_2017.filter(jan_2017.cost_per_mile.isNotNull())\n",
    "\n",
    "\n",
    "#minimum fare amounts according to NYC Taxi data standards\n",
    "jan_2017 = jan_2017.filter((jan_2017.fare_amount >= 2.50))\n",
    "jan_2017 = jan_2017.filter(jan_2017.improvement_surcharge >= 0.3)\n",
    "jan_2017 = jan_2017.filter(jan_2017.mta_tax >= 0.5)\n",
    "\n",
    "#maximum fare amount, no (logical) fares were greater than 600 although some tips might be \n",
    "#jan_2017 = jan_2017.filter((jan_2017.fare_amount < 600.0))\n",
    "#all trips being filtered out of the max cost per mile going < 0.1 miles \n",
    "#there were MANY trips that had a cost per mile of 1733.3334 with the total trip distance being exactly 0.03 and the fare amount being exactly 52\n",
    "\n",
    "# jan_2017.count()\n",
    "\n",
    "\n",
    "#jan_2017.describe(\"fare_amount\").show()\n",
    "\n",
    "#jan_2017.describe(\"DOLocationID\").show()\n",
    "\n",
    "#jan_2017.count()\n",
    "#0.646167527% of trips invalidated using basic filters of fare amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing money description\n",
    "#jan_2017.describe(\"missing_money\").show()\n",
    "#jan_2017.sort('missing_money', ascending=False).select([\"missing_money\"]).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.sort('fare_amount', ascending=False).select([\"fare_amount\", \"trip_distance\", \"cost_per_mile\"]).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.sort('trip_distance', ascending=False).select([\"fare_amount\", \"trip_distance\", \"cost_per_mile\"]).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.describe(\"cost_per_mile\").show()\n",
    "\n",
    "#jan_2017.describe(\"miles_per_dollar\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.describe(\"tip_amount\").show()\n",
    "#jan_2017.sort('tip_amount', ascending=False).select(\"tip_amount\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.sort('cost_per_mile', ascending=False).select([\"miles_per_dollar\", \"cost_per_mile\", \"trip_distance\",  \"total_amount\",  \"fare_amount\", \"tip_amount\", \"tolls_amount\"]).show(50)\n",
    "#upper bound of cost per mile is currently  1733.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.sort('cost_per_mile', ascending=True).select([\"cost_per_mile\", \"trip_distance\",  \"total_amount\",  \"fare_amount\",\"extra\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\" ]).show(50)\n",
    "\n",
    "#lower bound of cost per mile is currently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.describe(\"total_amount\").show()\n",
    "#jan_2017.sort('total_amount', ascending=False).select(\"total_amount\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.describe(\"improvement_surcharge\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.describe(\"trip_distance\").show()\n",
    "#jan_2017.sort('trip_distance', ascending=False).select(\"trip_distance\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.select('tpep_pickup_datetime').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: short (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: short (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RateCodeID: short (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: short (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- PUBorough: string (nullable = true)\n",
      " |-- PUZone: string (nullable = true)\n",
      " |-- PUServiceZone: string (nullable = true)\n",
      " |-- PUneighbor: string (nullable = true)\n",
      " |-- uniqueIdColumn: long (nullable = false)\n",
      " |-- AirportPU: integer (nullable = false)\n",
      " |-- PUDate: date (nullable = true)\n",
      " |-- PUTime: string (nullable = true)\n",
      " |-- PUHour: integer (nullable = true)\n",
      " |-- PUMinute: integer (nullable = true)\n",
      " |-- MorningRushHour: integer (nullable = false)\n",
      " |-- EveningRushHour: integer (nullable = false)\n",
      " |-- PUDay: integer (nullable = true)\n",
      " |-- PU_DOW: short (nullable = true)\n",
      " |-- Weekend: integer (nullable = false)\n",
      " |-- WorkingHour: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#jan_2017.select('PUDate').distinct().show()\n",
    "jan_2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = spark.read.load('weather.txt', format=\"text\")\n",
    "#weather_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.createOrReplaceTempView('weather_data_sdf')\n",
    "\n",
    "#spark.sql('select * FROM weather_data_sdf').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = spark.sql('SELECT CAST(split(value, \",\")[0] as string) AS date, '\\\n",
    "                        'CAST(split(value, \",\")[1] as string) as time, '\\\n",
    "                        'CAST(split(value, \",\")[2] as float) as temp, '\\\n",
    "                        'CAST(split(value, \",\")[3] as float) as windchill, '\\\n",
    "                        'CAST(split(value, \",\")[4] as float) as dewpoint, '\\\n",
    "                        'CAST(split(value, \",\")[5] as float) as humidity, '\\\n",
    "                        'CAST(split(value, \",\")[6] as float) as pressure, '\\\n",
    "                        'CAST(split(value, \",\")[7] as float) as visibility, '\\\n",
    "                        'CAST(split(value, \",\")[8] as string) as windDir, '\\\n",
    "                        'CAST(split(value, \",\")[9] as float) as windSpeed, '\\\n",
    "                        'CAST(split(value, \",\")[10] as float) as gustSpeed, '\\\n",
    "                        'CAST(split(value, \",\")[11] as float) as Precip, '\\\n",
    "                        'CAST(split(value, \",\")[12] as string) as Events, '\\\n",
    "                        'CAST(split(value, \",\")[13] as string) as Conditions '\\\n",
    "                         'FROM weather_data_sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast date to date type\n",
    "weather_data = weather_data.withColumn(\"date\", weather_data.date.cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def period(x):\n",
    "    return split(split(x, ':')[1], \" \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toHour(x):\n",
    "    first_split = split(x, ':')\n",
    "    retval = first_split[0].cast(IntegerType()) % 12\n",
    "    return retval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data.withColumn(\"period\", period(\"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make hour military time\n",
    "weather_data = weather_data.withColumn(\"hour\", when(weather_data.period == 'PM', toHour(\"time\") + 12).otherwise(toHour(\"time\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill any nulls\n",
    "weather_data = weather_data.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make temporary views for joining\n",
    "weather_data.createOrReplaceTempView('weather_data_sdf')\n",
    "\n",
    "weather_data_pu = spark.sql('SELECT date AS PUTempdate, '\\\n",
    "                            'time as PUTemptime, ' \\\n",
    "                            'temp as PUtemp, '\\\n",
    "                            'windchill as PUwindchill, '\\\n",
    "                            'dewpoint as PUdewpoint, '\\\n",
    "                            'pressure as PUpressure, '\\\n",
    "                            'visibility as PUvisibility, '\\\n",
    "                            'windDir as PUwindDir, '\\\n",
    "                            'gustSpeed as PUgustSpeed, '\\\n",
    "                            'Precip as PUPrecip, '\\\n",
    "                            'Events as PUEvents, '\\\n",
    "                            'Conditions as PUConditions, '\\\n",
    "                            'period as PUperiod, '\\\n",
    "                            'hour as PUTemphour '\\\n",
    "                            'FROM weather_data_sdf')\n",
    "\n",
    "# weather_data_do = spark.sql('SELECT date AS DOTempdate, '\\\n",
    "#                             'time as DOTemptime, ' \\\n",
    "#                             'temp as DOtemp, '\\\n",
    "#                             'windchill as DOwindchill, '\\\n",
    "#                             'dewpoint as DOdewpoint, '\\\n",
    "#                             'pressure as DOpressure, '\\\n",
    "#                             'visibility as DOvisibility, '\\\n",
    "#                             'windDir as DOwindDir, '\\\n",
    "#                             'gustSpeed as DOgustSpeed, '\\\n",
    "#                             'Precip as DOPrecip, '\\\n",
    "#                             'Events as DOEvents, '\\\n",
    "#                             'Conditions as DOConditions, '\\\n",
    "#                             'period as DOperiod, '\\\n",
    "#                             'hour as DOTemphour '\\\n",
    "#                             'FROM weather_data_sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.join(weather_data_pu, (jan_2017.PUDate == weather_data_pu.PUTempdate) & \\\n",
    "                         (jan_2017.PUHour == weather_data_pu.PUTemphour), \"left_outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.dropDuplicates(['uniqueIdColumn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan_2017 = jan_2017.join(weather_data_do, (jan_2017.DODate == weather_data_do.DOTempdate) & \\\n",
    "#                          (jan_2017.DOHour == weather_data_do.DOTemphour), \"left_outer\")\n",
    "# jan_2017.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: short (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: short (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RateCodeID: short (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: short (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- PUBorough: string (nullable = true)\n",
      " |-- PUZone: string (nullable = true)\n",
      " |-- PUServiceZone: string (nullable = true)\n",
      " |-- PUneighbor: string (nullable = true)\n",
      " |-- uniqueIdColumn: long (nullable = false)\n",
      " |-- AirportPU: integer (nullable = false)\n",
      " |-- PUDate: date (nullable = true)\n",
      " |-- PUTime: string (nullable = true)\n",
      " |-- PUHour: integer (nullable = true)\n",
      " |-- PUMinute: integer (nullable = true)\n",
      " |-- MorningRushHour: integer (nullable = false)\n",
      " |-- EveningRushHour: integer (nullable = false)\n",
      " |-- PUDay: integer (nullable = true)\n",
      " |-- PU_DOW: short (nullable = true)\n",
      " |-- Weekend: integer (nullable = false)\n",
      " |-- WorkingHour: integer (nullable = false)\n",
      " |-- PUTempdate: date (nullable = true)\n",
      " |-- PUTemptime: string (nullable = true)\n",
      " |-- PUtemp: float (nullable = true)\n",
      " |-- PUwindchill: float (nullable = true)\n",
      " |-- PUdewpoint: float (nullable = true)\n",
      " |-- PUpressure: float (nullable = true)\n",
      " |-- PUvisibility: float (nullable = true)\n",
      " |-- PUwindDir: string (nullable = true)\n",
      " |-- PUgustSpeed: float (nullable = true)\n",
      " |-- PUPrecip: float (nullable = true)\n",
      " |-- PUEvents: string (nullable = true)\n",
      " |-- PUConditions: string (nullable = true)\n",
      " |-- PUperiod: string (nullable = true)\n",
      " |-- PUTemphour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jan_2017.printSchema()\n",
    "\n",
    "#extra, payment type, fare amount, mta_tax, tip_amount, tollsamount, total_amount, improvement surcharge\n",
    "\n",
    "# Categorical Features\n",
    "# RateCodeID\n",
    "# store_and_fwd_flag\n",
    "# PULocationID\n",
    "# DOLocationID\n",
    "# LocationID (1 to 256)\n",
    "# PUBorough (comes from taxi+_lookup_zone)\n",
    "# PUZone (Name for Location ID)\n",
    "# PUServiceZone (Categorical)\n",
    "# PUNeighbor (Demographics Neighborhood)\n",
    "# PUDay (1-365)\n",
    "# PU_DOW (Day of week)\n",
    "# PUEvents\n",
    "# PUConditions\n",
    "# PUPeriod (AM or PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017.createOrReplaceTempView('jan_2017_sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUdemographics = spark.read.format(\"csv\").load('demographics.csv', header = True).cache()\n",
    "#DOdemographics = spark.read.format(\"csv\").load('demographics.csv', header = True).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUnames = PUdemographics.schema.names\n",
    "i = 0\n",
    "for name in PUnames:\n",
    "    if (i != 0):\n",
    "        PUdemographics = PUdemographics.withColumn(\"PU\" + name, col(name).cast(FloatType())).drop(name)\n",
    "  #      DOdemographics = DOdemographics.withColumn(\"DO\" + name, col(name).cast(FloatType())).drop(name)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- PUalone_hhld: float (nullable = true)\n",
      " |-- PUbachelor_higher: float (nullable = true)\n",
      " |-- PUbornstate: float (nullable = true)\n",
      " |-- PUcarfree: float (nullable = true)\n",
      " |-- PUcommutetime: float (nullable = true)\n",
      " |-- PUdisabled: float (nullable = true)\n",
      " |-- PUdisconnected: float (nullable = true)\n",
      " |-- PUforeign: float (nullable = true)\n",
      " |-- PUgross_rent_adj: float (nullable = true)\n",
      " |-- PUhhu18: float (nullable = true)\n",
      " |-- PUhomeownership: float (nullable = true)\n",
      " |-- PUhousing_units: float (nullable = true)\n",
      " |-- PUincome_diversity_ratio: float (nullable = true)\n",
      " |-- PUlaborforcerate: float (nullable = true)\n",
      " |-- PUmedhhincome_adj: float (nullable = true)\n",
      " |-- PUmedhhincome_own_adj: float (nullable = true)\n",
      " |-- PUmedhhincome_rent_adj: float (nullable = true)\n",
      " |-- PUnohsdiploma: float (nullable = true)\n",
      " |-- PUpark_share: float (nullable = true)\n",
      " |-- PUpasian: float (nullable = true)\n",
      " |-- PUpblack: float (nullable = true)\n",
      " |-- PUphisp: float (nullable = true)\n",
      " |-- PUpop65: float (nullable = true)\n",
      " |-- PUpopulation: float (nullable = true)\n",
      " |-- PUpopulation_density: float (nullable = true)\n",
      " |-- PUpov65older: float (nullable = true)\n",
      " |-- PUpovrate: float (nullable = true)\n",
      " |-- PUpovunder18: float (nullable = true)\n",
      " |-- PUprof_pct_ela: float (nullable = true)\n",
      " |-- PUprof_pct_math: float (nullable = true)\n",
      " |-- PUprop_rt: float (nullable = true)\n",
      " |-- PUpwhite: float (nullable = true)\n",
      " |-- PUrdindex: float (nullable = true)\n",
      " |-- PUrent_pct_nycha: float (nullable = true)\n",
      " |-- PUrentvacrate: float (nullable = true)\n",
      " |-- PUserious_viol_rate: float (nullable = true)\n",
      " |-- PUsevcrowd: float (nullable = true)\n",
      " |-- PUsubway_share: float (nullable = true)\n",
      " |-- PUtot_rt: float (nullable = true)\n",
      " |-- PUtotal_viol_rate: float (nullable = true)\n",
      " |-- PUunemprate: float (nullable = true)\n",
      " |-- PUviol_rt: float (nullable = true)\n",
      " |-- PUvolume_al: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PUdemographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = jan_2017.join(PUdemographics, jan_2017.PUneighbor == PUdemographics.neighborhood, \"left_outer\")\n",
    "jan_2017 = jan_2017.dropDuplicates(['uniqueIdColumn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017 = jan_2017.join(DOdemographics, jan_2017.DOneighbor == DOdemographics.DOneighborhood, \"left_outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan_2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(jan_2017.schema.names)\n",
    "\n",
    "# jan_2017.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan_2017.createOrReplaceTempView('jan_2017_cleaning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select * FROM jan_2017_cleaning WHERE PUneighbor == \"airport\"').show()\n",
    "\n",
    "\n",
    "#NA\n",
    "#NV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql('select PUZone, DOZone, count(*) FROM jan_2017_cleaning WHERE (PUBorough != \"Manhattan\") OR (DOBorough != \"Manhattan\")  GROUP BY 1, 2 ORDER BY COUNT(*) DESC').cache().show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select PUZone, DOZone, count(*) FROM jan_2017_cleaning  GROUP BY 1, 2 ORDER BY COUNT(*) ASC').cache().show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_hours = spark.sql('select PUHour, count(*) FROM jan_2017_cleaning GROUP BY 1 ORDER BY COUNT(*) DESC').cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_hours_per_week = spark.sql('select PU_DOW, PUHour, count(*) FROM jan_2017_cleaning GROUP BY 1, 2 ORDER BY COUNT(*) DESC').cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_hours_per_week.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hours_per_day = spark.sql('select PUHour, count(*) FROM jan_2017_cleaning GROUP BY 1 ORDER BY PUHour ASC ').cache()\n",
    "# hours_per_day.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hours_per_week.show(168)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # create some random data\n",
    "# y = np.array(hours_per_week.select('count(1)').collect())\n",
    "# x = np.arange(len(y))\n",
    "\n",
    "\n",
    "\n",
    "# # plot it\n",
    "# fig, ax = plt.subplots(1,1,figsize=(10,3))\n",
    "# plt.plot(y, color='k')\n",
    "# plt.xticks(np.arange(min(x), max(x)+1, 12.0))\n",
    "\n",
    "\n",
    "# #show it\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, linewidth=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps\n",
    "#dropping fields that related to drop off (except DOLocationID which is what we're trying to predict)\n",
    "\n",
    "#one hot encode\n",
    "#store all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(input_sdf, col_name):\n",
    "    if (col_name == \"PUZone\"):\n",
    "        return input_sdf\n",
    "    else:\n",
    "        i = 0\n",
    "        col_vals = input_sdf.select(col_name).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "        for val in col_vals:\n",
    "            i += 1\n",
    "            input_sdf = input_sdf.withColumn(\"{0}_is_{1}\".format(col_name, val), \\\n",
    "                                           F.when(input_sdf[col_name] == val, 1).otherwise(0))\n",
    "        return input_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: short (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: short (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RateCodeID: short (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: short (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- PUBorough: string (nullable = true)\n",
      " |-- PUZone: string (nullable = true)\n",
      " |-- PUServiceZone: string (nullable = true)\n",
      " |-- PUneighbor: string (nullable = true)\n",
      " |-- uniqueIdColumn: long (nullable = false)\n",
      " |-- AirportPU: integer (nullable = false)\n",
      " |-- PUDate: date (nullable = true)\n",
      " |-- PUTime: string (nullable = true)\n",
      " |-- PUHour: integer (nullable = true)\n",
      " |-- PUMinute: integer (nullable = true)\n",
      " |-- MorningRushHour: integer (nullable = false)\n",
      " |-- EveningRushHour: integer (nullable = false)\n",
      " |-- PUDay: integer (nullable = true)\n",
      " |-- PU_DOW: short (nullable = true)\n",
      " |-- Weekend: integer (nullable = false)\n",
      " |-- WorkingHour: integer (nullable = false)\n",
      " |-- PUTempdate: date (nullable = true)\n",
      " |-- PUTemptime: string (nullable = true)\n",
      " |-- PUtemp: float (nullable = true)\n",
      " |-- PUwindchill: float (nullable = true)\n",
      " |-- PUdewpoint: float (nullable = true)\n",
      " |-- PUpressure: float (nullable = true)\n",
      " |-- PUvisibility: float (nullable = true)\n",
      " |-- PUwindDir: string (nullable = true)\n",
      " |-- PUgustSpeed: float (nullable = true)\n",
      " |-- PUPrecip: float (nullable = true)\n",
      " |-- PUEvents: string (nullable = true)\n",
      " |-- PUConditions: string (nullable = true)\n",
      " |-- PUperiod: string (nullable = true)\n",
      " |-- PUTemphour: integer (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- PUalone_hhld: float (nullable = true)\n",
      " |-- PUbachelor_higher: float (nullable = true)\n",
      " |-- PUbornstate: float (nullable = true)\n",
      " |-- PUcarfree: float (nullable = true)\n",
      " |-- PUcommutetime: float (nullable = true)\n",
      " |-- PUdisabled: float (nullable = true)\n",
      " |-- PUdisconnected: float (nullable = true)\n",
      " |-- PUforeign: float (nullable = true)\n",
      " |-- PUgross_rent_adj: float (nullable = true)\n",
      " |-- PUhhu18: float (nullable = true)\n",
      " |-- PUhomeownership: float (nullable = true)\n",
      " |-- PUhousing_units: float (nullable = true)\n",
      " |-- PUincome_diversity_ratio: float (nullable = true)\n",
      " |-- PUlaborforcerate: float (nullable = true)\n",
      " |-- PUmedhhincome_adj: float (nullable = true)\n",
      " |-- PUmedhhincome_own_adj: float (nullable = true)\n",
      " |-- PUmedhhincome_rent_adj: float (nullable = true)\n",
      " |-- PUnohsdiploma: float (nullable = true)\n",
      " |-- PUpark_share: float (nullable = true)\n",
      " |-- PUpasian: float (nullable = true)\n",
      " |-- PUpblack: float (nullable = true)\n",
      " |-- PUphisp: float (nullable = true)\n",
      " |-- PUpop65: float (nullable = true)\n",
      " |-- PUpopulation: float (nullable = true)\n",
      " |-- PUpopulation_density: float (nullable = true)\n",
      " |-- PUpov65older: float (nullable = true)\n",
      " |-- PUpovrate: float (nullable = true)\n",
      " |-- PUpovunder18: float (nullable = true)\n",
      " |-- PUprof_pct_ela: float (nullable = true)\n",
      " |-- PUprof_pct_math: float (nullable = true)\n",
      " |-- PUprop_rt: float (nullable = true)\n",
      " |-- PUpwhite: float (nullable = true)\n",
      " |-- PUrdindex: float (nullable = true)\n",
      " |-- PUrent_pct_nycha: float (nullable = true)\n",
      " |-- PUrentvacrate: float (nullable = true)\n",
      " |-- PUserious_viol_rate: float (nullable = true)\n",
      " |-- PUsevcrowd: float (nullable = true)\n",
      " |-- PUsubway_share: float (nullable = true)\n",
      " |-- PUtot_rt: float (nullable = true)\n",
      " |-- PUtotal_viol_rate: float (nullable = true)\n",
      " |-- PUunemprate: float (nullable = true)\n",
      " |-- PUviol_rt: float (nullable = true)\n",
      " |-- PUvolume_al: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical Features\n",
    "# RateCodeID\n",
    "# store_and_fwd_flag\n",
    "# PULocationID\n",
    "# DOLocationID\n",
    "# LocationID (1 to 256)\n",
    "# PUBorough (comes from taxi+_lookup_zone)\n",
    "# PUZone (Name for Location ID)\n",
    "# PUServiceZone (Categorical)\n",
    "# PUNeighbor (Demographics Neighborhood)\n",
    "# PUDay (1-365)\n",
    "# PU_DOW (Day of week)\n",
    "# PUEvents\n",
    "# PUConditions\n",
    "# PUPeriod (AM or PM)\n",
    "jan_2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding PUZone\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUZone')\n",
    "print('done encoding PUZone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding RateCodeID\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'RateCodeID')\n",
    "print('done encoding RateCodeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding store_and_fwd_flag\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'store_and_fwd_flag')\n",
    "print('done encoding store_and_fwd_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PULocationID')\n",
    "print('done encoding PULocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    encoding 125\n",
      "    encoding 7\n",
      "    encoding 124\n",
      "    encoding 51\n",
      "    encoding 169\n",
      "    encoding 205\n",
      "    encoding 234\n",
      "    encoding 54\n",
      "    encoding 232\n",
      "    encoding 15\n",
      "    encoding 155\n",
      "    encoding 132\n",
      "    encoding 154\n",
      "    encoding 200\n",
      "    encoding 101\n",
      "    encoding 11\n",
      "    encoding 138\n",
      "    encoding 69\n",
      "    encoding 29\n",
      "    encoding 42\n",
      "    encoding 112\n",
      "    encoding 87\n",
      "    encoding 73\n",
      "    encoding 64\n",
      "    encoding 3\n",
      "    encoding 113\n",
      "    encoding 30\n",
      "    encoding 34\n",
      "    encoding 133\n",
      "    encoding 162\n",
      "    encoding 59\n",
      "    encoding 146\n",
      "    encoding 250\n",
      "    encoding 139\n",
      "    encoding 8\n",
      "    encoding 160\n",
      "    encoding 258\n",
      "    encoding 22\n",
      "    encoding 28\n",
      "    encoding 203\n",
      "    encoding 184\n",
      "    encoding 85\n",
      "    encoding 35\n",
      "    encoding 16\n",
      "    encoding 52\n",
      "    encoding 251\n",
      "    encoding 183\n",
      "    encoding 171\n",
      "    encoding 187\n",
      "    encoding 71\n",
      "    encoding 188\n",
      "    encoding 98\n",
      "    encoding 223\n",
      "    encoding 195\n",
      "    encoding 47\n",
      "    encoding 99\n",
      "    encoding 107\n",
      "    encoding 110\n",
      "    encoding 214\n",
      "    encoding 179\n",
      "    encoding 248\n",
      "    encoding 202\n",
      "    encoding 96\n",
      "    encoding 221\n",
      "    encoding 43\n",
      "    encoding 5\n",
      "    encoding 163\n",
      "    encoding 31\n",
      "    encoding 100\n",
      "    encoding 18\n",
      "    encoding 70\n",
      "    encoding 174\n",
      "    encoding 206\n",
      "    encoding 168\n",
      "    encoding 224\n",
      "    encoding 218\n",
      "    encoding 61\n",
      "    encoding 27\n",
      "    encoding 75\n",
      "    encoding 219\n",
      "    encoding 166\n",
      "    encoding 140\n",
      "    encoding 17\n",
      "    encoding 126\n",
      "    encoding 131\n",
      "    encoding 26\n",
      "    encoding 227\n",
      "    encoding 120\n",
      "    encoding 46\n",
      "    encoding 130\n",
      "    encoding 164\n",
      "    encoding 147\n",
      "    encoding 207\n",
      "    encoding 78\n",
      "    encoding 208\n",
      "    encoding 228\n",
      "    encoding 77\n",
      "    encoding 89\n",
      "    encoding 198\n",
      "    encoding 136\n",
      "    encoding 257\n",
      "    encoding 118\n",
      "    encoding 6\n",
      "    encoding 185\n",
      "    encoding 230\n",
      "    encoding 256\n",
      "    encoding 201\n",
      "    encoding 177\n",
      "    encoding 68\n",
      "    encoding 246\n",
      "    encoding 90\n",
      "    encoding 229\n",
      "    encoding 244\n",
      "    encoding 60\n",
      "    encoding 194\n",
      "    encoding 19\n",
      "    encoding 41\n",
      "    encoding 128\n",
      "    encoding 23\n",
      "    encoding 102\n",
      "    encoding 55\n",
      "    encoding 238\n",
      "    encoding 263\n",
      "    encoding 111\n",
      "    encoding 220\n",
      "    encoding 197\n",
      "    encoding 167\n",
      "    encoding 95\n",
      "    encoding 93\n",
      "    encoding 40\n",
      "    encoding 38\n",
      "    encoding 25\n",
      "    encoding 189\n",
      "    encoding 233\n",
      "    encoding 190\n",
      "    encoding 135\n",
      "    encoding 156\n",
      "    encoding 44\n",
      "    encoding 144\n",
      "    encoding 176\n",
      "    encoding 82\n",
      "    encoding 241\n",
      "    encoding 115\n",
      "    encoding 193\n",
      "    encoding 53\n",
      "    encoding 245\n",
      "    encoding 231\n",
      "    encoding 92\n",
      "    encoding 122\n",
      "    encoding 247\n",
      "    encoding 108\n",
      "    encoding 117\n",
      "    encoding 86\n",
      "    encoding 58\n",
      "    encoding 261\n",
      "    encoding 204\n",
      "    encoding 81\n",
      "    encoding 114\n",
      "    encoding 33\n",
      "    encoding 242\n",
      "    encoding 213\n",
      "    encoding 150\n",
      "    encoding 170\n",
      "    encoding 178\n",
      "    encoding 48\n",
      "    encoding 259\n",
      "    encoding 153\n",
      "    encoding 217\n",
      "    encoding 243\n",
      "    encoding 148\n",
      "    encoding 141\n",
      "    encoding 173\n",
      "    encoding 180\n",
      "    encoding 240\n",
      "    encoding 209\n",
      "    encoding 159\n",
      "    encoding 239\n",
      "    encoding 97\n",
      "    encoding 158\n",
      "    encoding 106\n",
      "    encoding 67\n",
      "    encoding 236\n",
      "    encoding 84\n",
      "    encoding 143\n",
      "    encoding 79\n",
      "    encoding 24\n",
      "    encoding 9\n",
      "    encoding 212\n",
      "    encoding 116\n",
      "    encoding 32\n",
      "    encoding 186\n",
      "    encoding 152\n",
      "    encoding 88\n",
      "    encoding 134\n",
      "    encoding 149\n",
      "    encoding 1\n",
      "    encoding 237\n",
      "    encoding 20\n",
      "    encoding 142\n",
      "    encoding 56\n",
      "    encoding 127\n",
      "    encoding 36\n",
      "    encoding 211\n",
      "    encoding 10\n",
      "    encoding 37\n",
      "    encoding 165\n",
      "    encoding 49\n",
      "    encoding 255\n",
      "    encoding 222\n",
      "    encoding 253\n",
      "    encoding 172\n",
      "    encoding 181\n",
      "    encoding 63\n",
      "    encoding 65\n",
      "    encoding 225\n",
      "    encoding 235\n",
      "    encoding 265\n",
      "    encoding 4\n",
      "    encoding 121\n",
      "    encoding 39\n",
      "    encoding 252\n",
      "    encoding 210\n",
      "    encoding 62\n",
      "    encoding 12\n",
      "    encoding 83\n",
      "    encoding 123\n",
      "    encoding 215\n",
      "    encoding 109\n",
      "    encoding 249\n",
      "    encoding 13\n",
      "    encoding 157\n",
      "    encoding 260\n",
      "    encoding 191\n",
      "    encoding 14\n",
      "    encoding 21\n",
      "    encoding 182\n",
      "    encoding 66\n",
      "    encoding 264\n",
      "    encoding 94\n",
      "    encoding 175\n",
      "    encoding 91\n",
      "    encoding 137\n",
      "    encoding 74\n",
      "    encoding 72\n",
      "    encoding 161\n",
      "    encoding 151\n",
      "    encoding 262\n",
      "    encoding 129\n",
      "    encoding 76\n",
      "    encoding 196\n",
      "    encoding 2\n",
      "    encoding 254\n",
      "    encoding 192\n",
      "    encoding 226\n",
      "    encoding 80\n",
      "    encoding 50\n",
      "    encoding 145\n",
      "    encoding 45\n",
      "    encoding 57\n",
      "    encoding 216\n",
      "    encoding 119\n",
      "done encoding DOLocationID\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'DOLocationID')\n",
    "print('done encoding DOLocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    encoding 125\n",
      "    encoding 7\n",
      "    encoding 51\n",
      "    encoding 124\n",
      "    encoding 169\n",
      "    encoding 205\n",
      "    encoding 234\n",
      "    encoding 232\n",
      "    encoding 54\n",
      "    encoding 15\n",
      "    encoding 155\n",
      "    encoding 132\n",
      "    encoding 154\n",
      "    encoding 200\n",
      "    encoding 11\n",
      "    encoding 101\n",
      "    encoding 138\n",
      "    encoding 69\n",
      "    encoding 29\n",
      "    encoding 42\n",
      "    encoding 112\n",
      "    encoding 87\n",
      "    encoding 73\n",
      "    encoding 64\n",
      "    encoding 3\n",
      "    encoding 113\n",
      "    encoding 34\n",
      "    encoding 133\n",
      "    encoding 162\n",
      "    encoding 59\n",
      "    encoding 146\n",
      "    encoding 250\n",
      "    encoding 139\n",
      "    encoding 8\n",
      "    encoding 160\n",
      "    encoding 258\n",
      "    encoding 28\n",
      "    encoding 22\n",
      "    encoding 203\n",
      "    encoding 184\n",
      "    encoding 85\n",
      "    encoding 52\n",
      "    encoding 35\n",
      "    encoding 16\n",
      "    encoding 183\n",
      "    encoding 171\n",
      "    encoding 187\n",
      "    encoding 71\n",
      "    encoding 188\n",
      "    encoding 98\n",
      "    encoding 223\n",
      "    encoding 195\n",
      "    encoding 47\n",
      "    encoding 107\n",
      "    encoding 214\n",
      "    encoding 179\n",
      "    encoding 202\n",
      "    encoding 96\n",
      "    encoding 248\n",
      "    encoding 221\n",
      "    encoding 43\n",
      "    encoding 163\n",
      "    encoding 31\n",
      "    encoding 100\n",
      "    encoding 18\n",
      "    encoding 70\n",
      "    encoding 174\n",
      "    encoding 206\n",
      "    encoding 168\n",
      "    encoding 224\n",
      "    encoding 61\n",
      "    encoding 218\n",
      "    encoding 75\n",
      "    encoding 166\n",
      "    encoding 219\n",
      "    encoding 140\n",
      "    encoding 17\n",
      "    encoding 126\n",
      "    encoding 131\n",
      "    encoding 227\n",
      "    encoding 26\n",
      "    encoding 120\n",
      "    encoding 46\n",
      "    encoding 130\n",
      "    encoding 164\n",
      "    encoding 207\n",
      "    encoding 147\n",
      "    encoding 78\n",
      "    encoding 208\n",
      "    encoding 228\n",
      "    encoding 89\n",
      "    encoding 77\n",
      "    encoding 198\n",
      "    encoding 136\n",
      "    encoding 257\n",
      "    encoding 6\n",
      "    encoding 118\n",
      "    encoding 185\n",
      "    encoding 230\n",
      "    encoding 256\n",
      "    encoding 201\n",
      "    encoding 177\n",
      "    encoding 68\n",
      "    encoding 246\n",
      "    encoding 90\n",
      "    encoding 244\n",
      "    encoding 229\n",
      "    encoding 60\n",
      "    encoding 194\n",
      "    encoding 19\n",
      "    encoding 41\n",
      "    encoding 128\n",
      "    encoding 23\n",
      "    encoding 102\n",
      "    encoding 55\n",
      "    encoding 238\n",
      "    encoding 263\n",
      "    encoding 111\n",
      "    encoding 197\n",
      "    encoding 220\n",
      "    encoding 167\n",
      "    encoding 95\n",
      "    encoding 93\n",
      "    encoding 40\n",
      "    encoding 38\n",
      "    encoding 25\n",
      "    encoding 189\n",
      "    encoding 233\n",
      "    encoding 190\n",
      "    encoding 135\n",
      "    encoding 156\n",
      "    encoding 144\n",
      "    encoding 176\n",
      "    encoding 82\n",
      "    encoding 115\n",
      "    encoding 241\n",
      "    encoding 193\n",
      "    encoding 53\n",
      "    encoding 245\n",
      "    encoding 231\n",
      "    encoding 92\n",
      "    encoding 122\n",
      "    encoding 247\n",
      "    encoding 108\n",
      "    encoding 117\n",
      "    encoding 86\n",
      "    encoding 261\n",
      "    encoding 58\n",
      "    encoding 81\n",
      "    encoding 114\n",
      "    encoding 33\n",
      "    encoding 242\n",
      "    encoding 213\n",
      "    encoding 150\n",
      "    encoding 170\n",
      "    encoding 178\n",
      "    encoding 48\n",
      "    encoding 153\n",
      "    encoding 259\n",
      "    encoding 217\n",
      "    encoding 148\n",
      "    encoding 141\n",
      "    encoding 173\n",
      "    encoding 243\n",
      "    encoding 180\n",
      "    encoding 240\n",
      "    encoding 239\n",
      "    encoding 209\n",
      "    encoding 97\n",
      "    encoding 159\n",
      "    encoding 158\n",
      "    encoding 106\n",
      "    encoding 67\n",
      "    encoding 236\n",
      "    encoding 143\n",
      "    encoding 79\n",
      "    encoding 24\n",
      "    encoding 9\n",
      "    encoding 212\n",
      "    encoding 116\n",
      "    encoding 32\n",
      "    encoding 186\n",
      "    encoding 152\n",
      "    encoding 88\n",
      "    encoding 134\n",
      "    encoding 1\n",
      "    encoding 149\n",
      "    encoding 237\n",
      "    encoding 105\n",
      "    encoding 20\n",
      "    encoding 142\n",
      "    encoding 56\n",
      "    encoding 127\n",
      "    encoding 211\n",
      "    encoding 36\n",
      "    encoding 10\n",
      "    encoding 37\n",
      "    encoding 165\n",
      "    encoding 49\n",
      "    encoding 255\n",
      "    encoding 253\n",
      "    encoding 222\n",
      "    encoding 172\n",
      "    encoding 181\n",
      "    encoding 63\n",
      "    encoding 65\n",
      "    encoding 235\n",
      "    encoding 225\n",
      "    encoding 4\n",
      "    encoding 121\n",
      "    encoding 39\n",
      "    encoding 252\n",
      "    encoding 210\n",
      "    encoding 62\n",
      "    encoding 12\n",
      "    encoding 83\n",
      "    encoding 215\n",
      "    encoding 123\n",
      "    encoding 13\n",
      "    encoding 249\n",
      "    encoding 260\n",
      "    encoding 157\n",
      "    encoding 191\n",
      "    encoding 14\n",
      "    encoding 182\n",
      "    encoding 21\n",
      "    encoding 66\n",
      "    encoding 91\n",
      "    encoding 94\n",
      "    encoding 175\n",
      "    encoding 74\n",
      "    encoding 137\n",
      "    encoding 72\n",
      "    encoding 161\n",
      "    encoding 151\n",
      "    encoding 262\n",
      "    encoding 129\n",
      "    encoding 76\n",
      "    encoding 196\n",
      "    encoding 2\n",
      "    encoding 254\n",
      "    encoding 192\n",
      "    encoding 80\n",
      "    encoding 226\n",
      "    encoding 50\n",
      "    encoding 145\n",
      "    encoding 45\n",
      "    encoding 57\n",
      "    encoding 216\n",
      "    encoding 119\n",
      "done encoding LocationID\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'LocationID')\n",
    "print('done encoding LocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    encoding Queens\n",
      "    encoding EWR\n",
      "    encoding Brooklyn\n",
      "    encoding Staten Island\n",
      "    encoding Manhattan\n",
      "    encoding Bronx\n",
      "done encoding PUBorough\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUBorough')\n",
    "print('done encoding PUBorough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    encoding EWR\n",
      "    encoding Yellow Zone\n",
      "    encoding Airports\n",
      "    encoding Boro Zone\n",
      "done encoding PUServiceZone\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUServiceZone')\n",
    "print('done encoding PUServiceZone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUNeighbor')\n",
    "print('done encoding PUNeighbor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PU_DOW')\n",
    "print('done encoding PU_DOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding PUEvents\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUEvents')\n",
    "print('done encoding PUEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding PUConditions\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUConditions')\n",
    "print('done encoding PUConditions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding PUPeriod\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUPeriod')\n",
    "print('done encoding PUPeriod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done encoding PUDay\n"
     ]
    }
   ],
   "source": [
    "jan_2017 = one_hot(jan_2017, 'PUDay')\n",
    "print('done encoding PUDay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1276\n"
     ]
    }
   ],
   "source": [
    "print(len(jan_2017.schema.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(X, labels):\n",
    "        plt.scatter(X[:,0],X[:,1])\n",
    "        for i, txt in enumerate(labels):\n",
    "                plt.annotate(txt, (X[i,0],X[i,1]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA!!!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select Labels\n",
    "labels = jan_2017['PUZone']\n",
    "\n",
    "# Standardize everything\n",
    "sc = StandardScaler()\n",
    "jan_2017_std= sc.fit_transform(jan_2017)\n",
    "\n",
    "# Compute PCA with 2 Principal Components\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(jan_2017_std)\n",
    "jan_2017_PCA = pca.transform(jan_2017_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
